{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hBRWiSLzJ2eR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import optuna\n",
    "import pathlib\n",
    "import joblib as jl\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('/Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "R6tUKaiDJ2ip"
   },
   "outputs": [],
   "source": [
    "from DressipiChallenge.Recommenders.GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "from DressipiChallenge.Recommenders.KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from DressipiChallenge.Recommenders.NonPersonalizedRecommender import TopPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DressipiChallenge.Pipeline.data_extraction import get_dataframes\n",
    "from DressipiChallenge.Pipeline.data_splitting import train_val_split\n",
    "from DressipiChallenge.Pipeline.matrices_creation import create_URM\n",
    "from DressipiChallenge.Pipeline.utils import create_mapping, batch_compute_item_score, batch_recommend, get_mapped_sessions_to_recommend, get_items_to_exclude\n",
    "from DressipiChallenge.Pipeline.xgboost.xgboost_utils import load_xgboost_df, fit_models, flat_list, generate_predictions, rename_columns\n",
    "from DressipiChallenge.Pipeline.telegram_utils import telegram_bot_sendfile, telegram_bot_sendtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST CELLS XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCfh93lTkQXw",
    "outputId": "c725e8fe-d42d-46df-ba6a-31023ed48460"
   },
   "outputs": [],
   "source": [
    "# generate predictions on validation set. N.B: the df has mapped ids\n",
    "dataframes_list = generate_predictions(models, val_sessions_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "TBCllcP0onKR",
    "outputId": "82cfff43-0853-4f69-f28d-0a19ed9caf0c"
   },
   "outputs": [],
   "source": [
    "boosted_df = dataframes_list[0]\n",
    "\n",
    "for i in range(1, len(dataframes_list)):\n",
    "  boosted_df = pd.merge(boosted_df, dataframes_list[i], how='outer', on=['session_id', 'item_id'])\n",
    "\n",
    "boosted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "NUk6jPRjkQZs",
    "outputId": "9e6c66c5-bb83-4ec7-aaa2-a22d722e4cc2"
   },
   "outputs": [],
   "source": [
    "# add missing purchases, drop duplicates, and create target\n",
    "val_purchases = train_purchases_df[\n",
    "    (train_purchases_df.date >= '2021-05-01') & (train_purchases_df.date < '2021-06-01')][['session_id', 'item_id']]\n",
    "\n",
    "val_purchases['session_id'] = val_purchases['session_id'].map(val_session_mapping)\n",
    "val_purchases['item_id'] = val_purchases['item_id'].map(item_mapping)\n",
    "val_purchases['target'] = 1\n",
    "\n",
    "merged_df = boosted_df.drop_duplicates(keep='last')\n",
    "merged_df = pd.merge(merged_df, val_purchases, how='outer', on=['session_id', 'item_id'])\n",
    "\n",
    "merged_df.rename_axis('index', inplace=True)\n",
    "merged_df.sort_values(by=['session_id', 'index'], inplace=True, na_position='first')\n",
    "merged_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "merged_df['target'] = merged_df['target'].fillna(False, inplace=False).astype('uint8')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genius version\n",
    "\n",
    "i=0\n",
    "\n",
    "filled_df = merged_df.copy()\n",
    "\n",
    "for col_index, column in enumerate(filled_df.columns):\n",
    "  if not (column in ['session_id', 'item_id', 'target']):\n",
    "    print(column)\n",
    "\n",
    "    selected_df = filled_df[filled_df[column].isna()].copy()\n",
    "\n",
    "    session_ids = np.unique(selected_df.session_id.to_list())\n",
    "    items_to_compute = np.unique(selected_df.item_id.to_list())\n",
    "\n",
    "    # print(\"len session_ids: \" + str(len(session_ids)))\n",
    "    # print(\"len items_to_compute: \" + str(len(items_to_compute)))\n",
    "\n",
    "    scores_list = batch_compute_item_score(models[i], session_ids, items_to_compute, 100)\n",
    "\n",
    "    scores_list = np.array(scores_list)\n",
    "\n",
    "    '''\n",
    "    def my_assign(x, value):\n",
    "      x[col_index] = value\n",
    "      return x\n",
    "      \n",
    "    for session_index, session_id in enumerate(tqdm(session_ids)):\n",
    "      # print(index)\n",
    "      current_section = selected_df[selected_df.session_id == session_id]\n",
    "      current_section = current_section.apply(lambda x: my_assign(x, scores_list[session_index, int(x[1])]), axis = 1, raw=True)\n",
    "      selected_df.update(current_section, errors='ignore')\n",
    "    '''\n",
    "\n",
    "    score_col = []\n",
    "\n",
    "    '''\n",
    "    for session_index, session_id in enumerate(tqdm(session_ids)):\n",
    "        current_items = selected_df[selected_df.session_id == session_id].item_id.to_list()\n",
    "        score_col.extend(scores_list[session_index, current_items])\n",
    "    '''\n",
    "\n",
    "    print('Obtaining item indices...')\n",
    "    # item_indices = [selected_df[selected_df.session_id == x].item_id.to_list() for x in session_ids]\n",
    "    item_lengths = selected_df.groupby(['session_id']).size().to_list()\n",
    "    # print(item_lengths)\n",
    "    item_indices = selected_df.item_id.to_list()\n",
    "    print('Obtaining session indices...')\n",
    "    session_indices = flat_list([[id] * length for id, length in zip(range(len(session_ids)), item_lengths)])\n",
    "    # session_indices = score_col.extend([id] * length for id, length in zip(range(len(session_ids)), item_lengths))\n",
    "    # item_indices = flat_list(item_indices)\n",
    "\n",
    "\n",
    "    print('Indexing...')\n",
    "    score_col = scores_list[session_indices, item_indices]\n",
    "\n",
    "    selected_df[column] = score_col\n",
    "\n",
    "    # print(\"Finished creating column array.\")\n",
    "\n",
    "    filled_df.fillna(selected_df, inplace=True)\n",
    "\n",
    "    i+=1\n",
    "    \n",
    "filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF merge version\n",
    "\n",
    "score_col = merged_df.columns\n",
    "# selected_df = pd.DataFrame()\n",
    "\n",
    "i=0\n",
    "\n",
    "for column in merged_df.columns:\n",
    "  if not (column in ['session_id', 'item_id']):\n",
    "    print(column)\n",
    "    selected_df = merged_df[merged_df[column].isna()].copy()\n",
    "\n",
    "    session_ids = np.unique(selected_df.session_id.to_list())\n",
    "    items_to_compute = np.unique(selected_df.item_id.to_list())\n",
    "    print(\"len session_ids: \" + str(len(session_ids)))\n",
    "    print(\"len items_to_compute: \" + str(len(items_to_compute)))\n",
    "\n",
    "    del selected_df \n",
    "    gc.collect()\n",
    "\n",
    "    scores_list = batch_compute_item_score(models[i], session_ids, items_to_compute, 100)\n",
    "\n",
    "    print(\"Finished computing scores.\")\n",
    "\n",
    "    replicated_session_ids = flat_list([([session]*len(items_to_compute)) for session in session_ids])\n",
    "    replicated_items_to_compute = items_to_compute * len(session_ids)\n",
    "\n",
    "    print(\"Finished creating column array.\")\n",
    "\n",
    "    del session_ids, items_to_compute\n",
    "    gc.collect()\n",
    "\n",
    "    df = pd.DataFrame({'session_id': replicated_session_ids, 'item_id': replicated_items_to_compute, column: scores_list})\n",
    "    print(\"Finished creating dataframe.\")\n",
    "\n",
    "    del scores_list, replicated_session_ids, replicated_items_to_compute\n",
    "    gc.collect()\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, df, how='left', on=['session_id', 'item_id'])\n",
    "    print(\"Finished merging.\")\n",
    "    print(merged_df)\n",
    "\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "    i+=1\n",
    "    \n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [[1,2,3], [4,5,6]]\n",
    "arr = np.array(arr)\n",
    "arr[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'session_id': [4, 5, 5], 'item_id': [0, 2, 2], 'item_score' : [np.NaN, np.NaN, np.NaN]})\n",
    "\n",
    "session_ids = [4, 5]\n",
    "\n",
    "arr = [[1,2,3], [4,5,6]]\n",
    "scores_list = np.array(arr)\n",
    "print(scores_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_indices = [df[df.session_id == x].item_id.to_list() for x in session_ids]\n",
    "item_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_indices = [[id] * len(items) for id, items in zip(session_ids, item_indices)]\n",
    "session_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list(item_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, session_id in enumerate(session_ids):\n",
    "      # print(index)\n",
    "      current_items = df[df.session_id == session_id].item_id.to_list()\n",
    "      print(scores_list[index, current_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_assign(x, value):\n",
    "      x[2] = value\n",
    "      print(x)\n",
    "      return x\n",
    "\n",
    "for index, session_id in enumerate(session_ids):\n",
    "      # print(index)\n",
    "      current_section = df[df.session_id == session_id]\n",
    "      current_section = current_section.apply(lambda x: my_assign(x, scores_list[index, int(x[1])]), axis = 1, raw=True)\n",
    "      # current_section.apply(lambda x: print(scores_list[index, int(x[1])]), axis=1, raw=True)\n",
    "      # current_section.apply(lambda x: print(x), axis=1, raw=True)\n",
    "      print(current_section)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory efficient version\n",
    "score_col = merged_df.columns\n",
    "# selected_df = pd.DataFrame()\n",
    "\n",
    "i=0\n",
    "\n",
    "for column in merged_df.columns:\n",
    "  if not (column in ['session_id', 'item_id']):\n",
    "    print(column)\n",
    "    selected_df = merged_df[merged_df[column].isna()].copy()\n",
    "\n",
    "    session_ids = np.unique(selected_df.session_id.to_list())\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    for id in tqdm(session_ids):\n",
    "      items_to_compute = selected_df[selected_df.session_id == id].item_id.to_list()\n",
    "      # print(\"len items_to_compute: \" + str(len(items_to_compute)))\n",
    "\n",
    "      temp_scores_list = single_compute_item_score(models[i], [id], items_to_compute)\n",
    "\n",
    "      scores_list.extend(temp_scores_list)\n",
    "\n",
    "      del items_to_compute, temp_scores_list\n",
    "      gc.collect()\n",
    "\n",
    "    print(\"Finished computing scores.\")\n",
    "    count = 0\n",
    "\n",
    "    if len(scores_list) != len(selected_df):\n",
    "      raise Exception('NUMBER OF SCORES DOES NOT MATCH')\n",
    "\n",
    "    for index in selected_df.index:\n",
    "      merged_df[column].iloc[index] = scores_list[count]\n",
    "      count += 1\n",
    "\n",
    "    del selected_df, scores_list, replicated_session_ids, replicated_items_to_compute\n",
    "    gc.collect()\n",
    "\n",
    "    print(merged_df)\n",
    "\n",
    "    i+=1\n",
    "    \n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "XLCu2samjcnd",
    "outputId": "d8525adc-559e-48bc-f6d4-74db1ff27632"
   },
   "outputs": [],
   "source": [
    "#TODO can the score be 0?\n",
    "merged_df[merged_df['item_score']==0.0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Ya_x0a00kpsE",
    "outputId": "3e3ef8e3-ae0e-4e88-b97b-fc39c7776a97"
   },
   "outputs": [],
   "source": [
    "merged_df[merged_df.session_id==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaVYQ-i4OCRB"
   },
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4-AZ0egSJ2ms"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVs read\n"
     ]
    }
   ],
   "source": [
    "item_features_df, train_sessions_df, train_purchases_df, test_sessions_df, candidate_items_df = get_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "yyr_JBYbbBXX"
   },
   "outputs": [],
   "source": [
    "train_set_df, val_set_df = train_val_split(train_sessions_df, train_purchases_df,\n",
    "                                               n_sets=1,\n",
    "                                               ts_start='2021-05-01', ts_end='2021-06-01',\n",
    "                                               return_discarded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WlNRVYCubBZR"
   },
   "outputs": [],
   "source": [
    "# create mapping\n",
    "item_mapping = create_mapping(item_features_df['item_id'], return_inverse_mapping=False)\n",
    "\n",
    "train_session_mapping = create_mapping(train_set_df['session_id'])\n",
    "\n",
    "val_session_mapping = create_mapping(val_set_df['session_id'])\n",
    "\n",
    "val_sessions_arr = get_mapped_sessions_to_recommend(val_set_df, val_session_mapping)\n",
    "\n",
    "# test_session_mapping = create_mapping(test_sessions_df['session_id'])\n",
    "# test_session_arr = get_mapped_sessions_to_recommend(test_sessions_df, test_session_mapping)\n",
    "\n",
    "candidates_val_ids = candidate_items_df['item_id'].values\n",
    "items_to_ignore = get_items_to_exclude(item_features_df, candidates_val_ids)\n",
    "mapped_items_to_ignore = [item_mapping[elem] for elem in items_to_ignore]\n",
    "\n",
    "val_purchases = train_purchases_df[\n",
    "        (train_purchases_df.date >= '2021-05-01') & (train_purchases_df.date < '2021-06-01')][['session_id', 'item_id']]\n",
    "val_purchases['session_id'] = val_purchases['session_id'].map(val_session_mapping)  \n",
    "val_purchases['item_id'] = val_purchases['item_id'].map(item_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Z6jwmyfikQT7"
   },
   "outputs": [],
   "source": [
    "# create URM_train\n",
    "URM_train = create_URM(train_set_df, train_session_mapping, item_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omBo-7yHkQV2",
    "outputId": "3123e753-90c9-439a-f6df-334508d1de84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3alphaRecommender: URM Detected 73 ( 0.3%) items with no interactions.\n",
      "TopPopRecommender: URM Detected 73 ( 0.3%) items with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 73 ( 0.3%) items with no interactions.\n"
     ]
    }
   ],
   "source": [
    "# define pre optimized models and best hyperparameters\n",
    "models = []\n",
    "models_hyp = []\n",
    "\n",
    "models.append(P3alphaRecommender(URM_train))\n",
    "models_hyp.append({'topK': 479, 'alpha': 1.1764856470188576, 'normalize_similarity': True})\n",
    "\n",
    "models.append(TopPop(URM_train))\n",
    "models_hyp.append({})  # TODO add if condition if model has no hyperparam\n",
    "\n",
    "models.append(ItemKNNCFRecommender(URM_train))\n",
    "models_hyp.append({'shrink': 500, 'similarity': 'asymmetric', 'feature_weighting': 'none', 'topK': 495, 'normalize': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "hL34oLXCkr0j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 23691 (100.0%), 4683.50 column/sec. Elapsed time 5.06 sec\n"
     ]
    }
   ],
   "source": [
    "# fit models on URM_train\n",
    "fit_models(models, models_hyp, mapped_items_to_ignore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:35<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Recommending...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:36<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Recommending...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:38<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Filling missing item_scores...\n",
      "Computing item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Computing item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 80.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Computing item scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "candidates_df, target_df = load_xgboost_df(val_purchases=val_purchases, models=models, cutoff=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates_df[(candidates_df.item_score_x != 0) & (candidates_df.item_score_y != 0) & (target_df.target == 1)]\n",
    "candidates_df = rename_columns(candidates_df, models)\n",
    "candidates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df[candidates_df.session_id == 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9PZreErzBPI"
   },
   "source": [
    "## K-Fold splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "61lsma6Oonqf",
    "outputId": "0d9ca126-207e-4bac-b733-a3da6437aea4"
   },
   "outputs": [],
   "source": [
    "def XGB_KFold_split(merged_df, n_splits = 5):\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "    target_df = merged_df[['target']].copy()\n",
    "    merged_df.drop(columns='target', inplace=True)\n",
    "\n",
    "    for train_index, val_index in group_kfold.split(merged_df, target_df, merged_df.session_id):\n",
    "        # print(\"TRAIN:\", train_index, \"VAL:\", val_index)\n",
    "        X_train, X_val = merged_df.iloc[train_index], merged_df.iloc[val_index]\n",
    "        y_train, y_val = target_df.iloc[train_index], target_df.iloc[val_index]\n",
    "        # print(X_train, X_val, y_train, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_zeros_candidates_df = candidates_df.copy()\n",
    "no_zeros_candidates_df[no_zeros_candidates_df.item_score_x == 0].item_score_x = np.NaN\n",
    "no_zeros_candidates_df[no_zeros_candidates_df.item_score_y == 0].item_score_y = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcandidates = xgb.DMatrix(\n",
    "    candidates_df.drop(columns=['session_id', 'item_id']),\n",
    "    label = target_df,\n",
    "    qid = candidates_df['session_id'],\n",
    "    nthread = -1,\n",
    "    missing = np.NaN,\n",
    "    # group = candidates_df.groupby(['session_id']).size().to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"verbosity\": 1,\n",
    "    \"validate_parameters\": True,\n",
    "\n",
    "    \"eta\": 1e-1, # learning rate\n",
    "    \"gamma\": 1e-3,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_child_weight\": 50,\n",
    "    \"max_delta_step\": 0,\n",
    "    \"subsample\": 1e-3,\n",
    "    \"sampling_method\": 'gradient_based',\n",
    "    \"colsample_bytree\": 1,\n",
    "    \"colsample_bylevel\": 1,\n",
    "    \"colsample_bynode\": 1,\n",
    "    \"lambda\": 1,\n",
    "    \"alpha\": 1e-8, # [0, inf]\n",
    "    \"tree_method\": 'gpu_hist',    \n",
    "    \n",
    "    \"objective\": 'rank:map',\n",
    "    \"eval_metric\": 'map@100',\n",
    "    \"random_state\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dcandidates,\n",
    "    num_boost_round=10,\n",
    "    # early_stopping_rounds = 100,\n",
    "    callbacks=[xgb.callback.EvaluationMonitor(show_stdv=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.eval(dcandidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-map@100:0.22276+0.03842\ttest-map@100:0.22294+0.03970\n",
      "[1]\ttrain-map@100:0.44050+0.00798\ttest-map@100:0.43962+0.01322\n",
      "[2]\ttrain-map@100:0.54255+0.01394\ttest-map@100:0.54191+0.01606\n",
      "[3]\ttrain-map@100:0.55049+0.00831\ttest-map@100:0.55030+0.00976\n",
      "[4]\ttrain-map@100:0.55347+0.00541\ttest-map@100:0.55323+0.00726\n",
      "[5]\ttrain-map@100:0.55505+0.00614\ttest-map@100:0.55468+0.00668\n",
      "[6]\ttrain-map@100:0.55503+0.00617\ttest-map@100:0.55475+0.00650\n",
      "[7]\ttrain-map@100:0.55785+0.00299\ttest-map@100:0.55749+0.00344\n",
      "[8]\ttrain-map@100:0.55870+0.00216\ttest-map@100:0.55832+0.00278\n",
      "[9]\ttrain-map@100:0.55878+0.00200\ttest-map@100:0.55851+0.00276\n"
     ]
    }
   ],
   "source": [
    "num_folds = 3\n",
    "group_kfold = GroupKFold(n_splits=num_folds).split(candidates_df.drop(columns=['session_id', 'item_id']), target_df, groups= candidates_df.session_id)\n",
    "\n",
    "# print(group_kfold)\n",
    "\n",
    "xgb_model = xgb.cv(\n",
    "    params,\n",
    "    dcandidates,\n",
    "    # folds = group_kfold,\n",
    "    num_boost_round=10,\n",
    "    nfold = num_folds,\n",
    "    # metrics = ['ndcg@100' 'map@100'],\n",
    "    early_stopping_rounds = 2,\n",
    "    # as_pandas=True,\n",
    "    callbacks=[xgb.callback.EvaluationMonitor(show_stdv=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.predict(dcandidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "predictions = (candidates_df.groupby('session_id').progress_apply(lambda x: xgb_model.predict(\n",
    "    xgb.DMatrix(\n",
    "    x.drop(columns=['session_id', 'item_id']),\n",
    "    # label = target_df,\n",
    "    # qid = candidates_df['session_id'],\n",
    "    nthread = -1,\n",
    "    missing = np.NaN,\n",
    "    # group = candidates_df.groupby(['session_id']).size().to_list(),\n",
    ")\n",
    ")))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for a in predictions.values:\n",
    "    scores.extend(a)\n",
    "    \n",
    "# inverted because later I need to sort in ascending order for customer_id\n",
    "candidates_df['score'] = [-a for a in scores]\n",
    "\n",
    "candidates_df['session_id'] = candidates_df['session_id'].astype('Int64')\n",
    "\n",
    "submission_df = candidates_df.sort_values(by=['session_id', 'score'], inplace=False, ascending=True)\n",
    "submission_df = submission_df.groupby('session_id').head(100)\n",
    "\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_hypertune(candidates_df, target_df, hyperparams_dict, n_iter = 200):\n",
    "\n",
    "    dcandidates = xgb.DMatrix(\n",
    "        candidates_df.drop(columns=['session_id', 'item_id']),\n",
    "        label = target_df,\n",
    "        qid = candidates_df['session_id'],\n",
    "        nthread = -1,\n",
    "        missing = np.NaN,\n",
    "    )\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Space:\n",
    "\n",
    "    def __init__(self):\n",
    "        raise NotImplemented\n",
    "\n",
    "    def set_trial(self, trial):\n",
    "        self.trial = trial\n",
    "\n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def suggest(self):\n",
    "        raise NotImplementedError\t\n",
    "\t\t\n",
    "class Range(Space):\n",
    "\n",
    "    def __init__(self, low=0, high=1, prior='uniform'):\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.prior = prior\n",
    "\n",
    "class Categorical(Space):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        if type(params) != list:\n",
    "            self.params = list(params)\n",
    "\n",
    "        self.params = params\n",
    "\n",
    "    def suggest(self):\n",
    "        return self.trial.suggest_categorical(self.name, self.params)\n",
    "\n",
    "class Integer(Range):\n",
    "\n",
    "    def __init__(self, low=0, high=1, prior='uniform', step=1):\n",
    "        super(Integer, self).__init__(low, high, prior)\n",
    "        self.step = step\n",
    "\n",
    "    def suggest(self):\n",
    "        return self.trial.suggest_int(self.name, self.low, self.high, self.step)\n",
    "\n",
    "class Real(Range):\n",
    "\n",
    "    def __init__(self, low=0, high=1, prior='uniform', step=None):\n",
    "        super(Real, self).__init__(low, high, prior)\n",
    "        self.log = True if self.prior == 'log-uniform' else False\n",
    "        self.step = None if self.log is True else step\n",
    "\n",
    "    def suggest(self):\n",
    "        return self.trial.suggest_float(self.name, self.low, self.high, step=self.step, log=self.log)\n",
    "    \n",
    "def suggest(trial, param_dict):\n",
    "\n",
    "    sampled = {}\n",
    "\n",
    "    for param, val in param_dict.items():\n",
    "        \n",
    "        if isinstance(val, Space):\n",
    "            val.set_name(param)\n",
    "            val.set_trial(trial)\n",
    "            sampled[param] = val.suggest()\n",
    "        else:\n",
    "            sampled[param] = val\n",
    "\n",
    "    return sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_hypertune (\n",
    "    candidates_df, target_df, xgb_hyp_params_dict = None, num_trials = 500, num_folds = 3, early_stopping_rounds = 100,\n",
    "    save_folder = \"./save\", study_name = 'study', resume=False, with_datetime = True,\n",
    "    telegram_notifications = True,\n",
    "    ):\n",
    "\n",
    "        class Hypertuner:\n",
    "\n",
    "            def __init__(self, dcandidates):\n",
    "                self.dcandidates = dcandidates\n",
    "    \n",
    "            def __call__(self, trial):\n",
    "\n",
    "                chosen_data = suggest(trial, xgb_hyp_params_dict)\n",
    "\n",
    "                print('[HYPERTUNE] Chosen parameters: ' + str(chosen_data))\n",
    "\n",
    "                xgb_model = xgb.cv(\n",
    "                    chosen_data,\n",
    "                    dcandidates,\n",
    "                    # folds = group_kfold,\n",
    "                    num_boost_round=10,\n",
    "                    nfold = num_folds,\n",
    "                    # metrics = ['ndcg@100' 'map@100'],\n",
    "                    early_stopping_rounds = early_stopping_rounds,\n",
    "                    as_pandas=True,\n",
    "                )\n",
    "\n",
    "                best_score = xgb_model.iloc[-1, -2]\n",
    "\n",
    "                print('[HYPERTUNE] Best mean validation score: ' + str(best_score))\n",
    "                print('[HYPERTUNE] Std of best validation score: ' + str(xgb_model.iloc[-1, -1]))\n",
    "\n",
    "                trial.set_user_attr(\"best_iteration\", xgb_model.index[-1])\n",
    "\n",
    "                del xgb_model\n",
    "\n",
    "                return best_score\n",
    "\n",
    "        class SaveCallback:\n",
    "\n",
    "            def __init__(self, std_name, param_name):\n",
    "                self.std_name=std_name\n",
    "                self.param_name = param_name\n",
    "\n",
    "            def __call__(self, study: optuna.Study, trial):\n",
    "                jl.dump(study, self.std_name)\n",
    "                jl.dump(study.best_trial.params, self.param_name)\n",
    "\n",
    "        class TelegramCallback:\n",
    "\n",
    "            def __init__(self, std_name):\n",
    "                self.best = 0\n",
    "                self.std_name=std_name\n",
    "\n",
    "            def __call__(self, study: optuna.Study, trial):\n",
    "                if study.best_value > self.best:\n",
    "                    self.best = study.best_value\n",
    "                    telegram_bot_sendtext(\"[XGBOOST] \" + \"HYPERPARAMETERS: \" + str(study.best_params) + ' MAP: ' + str(self.best))\n",
    "                    telegram_bot_sendfile(self.std_name, \"study_xgboost.pkl\")\n",
    "\n",
    "        pd.options.mode.chained_assignment = None # Disable SettingWithCopyWarning \n",
    "\n",
    "        if xgb_hyp_params_dict is None:\n",
    "            xgb_hyp_params_dict = {\n",
    "                \"sampling_method\": Categorical(['uniform', 'gradient_based']),\n",
    "                \"booster\": Categorical([\"gbtree\"]), # ['dart']\n",
    "                \"max_depth\": Integer(1, 8),\n",
    "                \"eta\": Real(1e-2, 1, prior='log-uniform'),\n",
    "                \"gamma\": Real(1e-9, 1e-1, prior='log-uniform'),\n",
    "                \"min_child_weight\": Integer(1, 100),\n",
    "                \"subsample\": Real(0.1, 1),\n",
    "                \"colsample_bytree\": Real(1e-6, 1, prior='log-uniform'), # [0,1]\n",
    "                \"colsample_bylevel\": Real(1e-6, 1, prior='log-uniform'), # [0,1]\n",
    "                \"colsample_bynode\": Real(1e-6, 1, prior='log-uniform'), # [0,1]\n",
    "                \"alpha\": Real(1e-9, 1, prior='log-uniform'), # [0, inf]\n",
    "                \"lambda\": Real(1e-9, 5, prior='log-uniform'),\n",
    "                # \"base_score\": 0, # [0, inf]\n",
    "                # \"num_parallel_tree\": 1, # [1, inf]\n",
    "            }\n",
    "\n",
    "            fixed_params = {\n",
    "                \"verbosity\": 1,\n",
    "                \"validate_parameters\": True,\n",
    "                \"objective\": 'rank:map',\n",
    "                \"eval_metric\": 'map@100',\n",
    "                \"tree_method\": 'gpu_hist',\n",
    "                \"random_state\": 10,\n",
    "                # \"gpu_id\": 0,\n",
    "                # \"n_jobs\": 4,\n",
    "            }\n",
    "\n",
    "            xgb_hyp_params_dict.update(fixed_params)\n",
    "        \n",
    "        else:\n",
    "            fixed_params = {k:v for k,v in xgb_hyp_params_dict.items() if not isinstance(v, (Real, Integer, Categorical, Range, Space))}\n",
    "        \n",
    "        dt = \"\"\n",
    "        if with_datetime:\n",
    "            dt = datetime.now().strftime('%d-%m-%y_%H_%M_%S')\n",
    "            dt = dt + '_'\n",
    "        \n",
    "        save_folder = os.path.join(save_folder, 'xgboost')\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "            study = optuna.create_study(direction='maximize')\n",
    "            study_path = os.path.join(save_folder, dt + study_name + '.pkl')\n",
    "            param_path = os.path.join(save_folder, dt + study_name + \"_best_parameters\" + '.pkl')\n",
    "        else:\n",
    "            matches = list(pathlib.Path(os.path.join(save_folder)).glob('*' + study_name + '.pkl'))\n",
    "            param_path = os.path.join(save_folder, dt + study_name + \"_best_parameters\" + '.pkl')\n",
    "            if resume and len(matches) > 0:\n",
    "                filename = max([str(m) for m in matches], key=os.path.getctime)\n",
    "                print('[HYPERTUNE] Loading from file: ' + filename)\n",
    "                with open(filename, 'rb') as f:\n",
    "                    study = jl.load(f)\n",
    "                study_path = filename\n",
    "            else:\n",
    "                study = optuna.create_study(direction='maximize')\n",
    "                study_path = os.path.join(save_folder, dt + study_name + '.pkl')\n",
    "            \n",
    "        callbacks = []\n",
    "        callbacks.append(SaveCallback(study_path, param_path))\n",
    "\n",
    "        if telegram_notifications:\n",
    "            callbacks.append(TelegramCallback(study_path)) \n",
    "\n",
    "        dcandidates = xgb.DMatrix(\n",
    "            candidates_df.drop(columns=['session_id', 'item_id']),\n",
    "            label = target_df,\n",
    "            qid = candidates_df['session_id'],\n",
    "            nthread = -1,\n",
    "            missing = np.NaN,\n",
    "        )\n",
    "\n",
    "        study.optimize(Hypertuner(dcandidates), n_trials=num_trials, callbacks=callbacks)\n",
    "\n",
    "        best_iteration = study.best_trial.user_attrs['best_iteration']\n",
    "\n",
    "        if telegram_notifications:\n",
    "            telegram_bot_sendtext(\"[XGBOOST] \" + \"Best iteration : \" + str(best_iteration))\n",
    "            telegram_bot_sendtext(\"[XGBOOST] \" + \"Hypertuning finished.\")\n",
    "\n",
    "        best_params = {**fixed_params, **study.best_params}\n",
    "\n",
    "        print(\"[HYPERTUNE] Best params: \", str(best_params))\n",
    "        print(\"[HYPERTUNE] Best iteration: \", str(best_iteration))\n",
    "\n",
    "        return best_params, best_iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-05-26 17:33:57,594]\u001B[0m A new study created in memory with name: no-name-e35ac42d-a680-4655-8bc5-c5d722032c76\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HYPERTUNE] Chosen parameters: {'sampling_method': 'gradient_based', 'booster': 'gbtree', 'max_depth': 3, 'eta': 0.9257156997305257, 'gamma': 0.02407487027326196, 'min_child_weight': 36, 'subsample': 0.981773586148581, 'colsample_bytree': 0.0011791953844212896, 'colsample_bylevel': 0.00025692164954869745, 'colsample_bynode': 0.0012653925913366532, 'alpha': 1.7962231690265088e-07, 'lambda': 2.4701979133045098e-08, 'verbosity': 1, 'validate_parameters': True, 'objective': 'rank:map', 'eval_metric': 'map@100', 'tree_method': 'gpu_hist', 'random_state': 10}\n",
      "[0]\ttrain-map@100:0.01473+0.00005\ttest-map@100:0.01473+0.00012\n",
      "[1]\ttrain-map@100:0.03118+0.00034\ttest-map@100:0.03123+0.00163\n",
      "[2]\ttrain-map@100:0.03729+0.00037\ttest-map@100:0.03733+0.00158\n",
      "[3]\ttrain-map@100:0.03733+0.00040\ttest-map@100:0.03735+0.00157\n",
      "[4]\ttrain-map@100:0.43687+0.00051\ttest-map@100:0.43664+0.00415\n",
      "[5]\ttrain-map@100:0.45196+0.00141\ttest-map@100:0.45183+0.00347\n",
      "[6]\ttrain-map@100:0.49638+0.00129\ttest-map@100:0.49634+0.00444\n",
      "[7]\ttrain-map@100:0.50332+0.00070\ttest-map@100:0.50291+0.00370\n",
      "[8]\ttrain-map@100:0.50160+0.00323\ttest-map@100:0.50136+0.00299\n",
      "[9]\ttrain-map@100:0.50235+0.00342\ttest-map@100:0.50212+0.00294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-05-26 17:34:26,692]\u001B[0m Trial 0 finished with value: 0.5021159896284987 and parameters: {'sampling_method': 'gradient_based', 'booster': 'gbtree', 'max_depth': 3, 'eta': 0.9257156997305257, 'gamma': 0.02407487027326196, 'min_child_weight': 36, 'subsample': 0.981773586148581, 'colsample_bytree': 0.0011791953844212896, 'colsample_bylevel': 0.00025692164954869745, 'colsample_bynode': 0.0012653925913366532, 'alpha': 1.7962231690265088e-07, 'lambda': 2.4701979133045098e-08}. Best is trial 0 with value: 0.5021159896284987.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HYPERTUNE] Best mean validation score: 0.5021159896284987\n",
      "[HYPERTUNE] Std of best validation score: 0.002942936370632178\n",
      "[HYPERTUNE] Chosen parameters: {'sampling_method': 'uniform', 'booster': 'gbtree', 'max_depth': 7, 'eta': 0.11508675164077814, 'gamma': 4.340269343477574e-06, 'min_child_weight': 58, 'subsample': 0.38578554784066044, 'colsample_bytree': 6.53908135358264e-05, 'colsample_bylevel': 2.997260831289789e-06, 'colsample_bynode': 0.0013696607963351605, 'alpha': 0.02277670203546916, 'lambda': 0.0015398787077015416, 'verbosity': 1, 'validate_parameters': True, 'objective': 'rank:map', 'eval_metric': 'map@100', 'tree_method': 'gpu_hist', 'random_state': 10}\n",
      "[0]\ttrain-map@100:0.01518+0.00042\ttest-map@100:0.01518+0.00057\n",
      "[1]\ttrain-map@100:0.03100+0.00145\ttest-map@100:0.03086+0.00265\n",
      "[2]\ttrain-map@100:0.03641+0.00173\ttest-map@100:0.03627+0.00291\n",
      "[3]\ttrain-map@100:0.03626+0.00179\ttest-map@100:0.03609+0.00292\n",
      "[4]\ttrain-map@100:0.38053+0.00597\ttest-map@100:0.37946+0.00426\n",
      "[5]\ttrain-map@100:0.39458+0.00276\ttest-map@100:0.39331+0.00279\n",
      "[6]\ttrain-map@100:0.39421+0.00229\ttest-map@100:0.39289+0.00164\n",
      "[7]\ttrain-map@100:0.39502+0.00266\ttest-map@100:0.39409+0.00348\n",
      "[8]\ttrain-map@100:0.39030+0.00264\ttest-map@100:0.38910+0.00379\n",
      "[9]\ttrain-map@100:0.40186+0.00334\ttest-map@100:0.40074+0.00433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-05-26 17:34:57,975]\u001B[0m Trial 1 finished with value: 0.4007390203132586 and parameters: {'sampling_method': 'uniform', 'booster': 'gbtree', 'max_depth': 7, 'eta': 0.11508675164077814, 'gamma': 4.340269343477574e-06, 'min_child_weight': 58, 'subsample': 0.38578554784066044, 'colsample_bytree': 6.53908135358264e-05, 'colsample_bylevel': 2.997260831289789e-06, 'colsample_bynode': 0.0013696607963351605, 'alpha': 0.02277670203546916, 'lambda': 0.0015398787077015416}. Best is trial 0 with value: 0.5021159896284987.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HYPERTUNE] Best mean validation score: 0.4007390203132586\n",
      "[HYPERTUNE] Std of best validation score: 0.004333112525448945\n",
      "[HYPERTUNE] Chosen parameters: {'sampling_method': 'gradient_based', 'booster': 'gbtree', 'max_depth': 3, 'eta': 0.9658354523530484, 'gamma': 1.5152916400990294e-08, 'min_child_weight': 68, 'subsample': 0.5024214920078056, 'colsample_bytree': 0.04087340605067627, 'colsample_bylevel': 0.000852725826709348, 'colsample_bynode': 0.5871113479525519, 'alpha': 2.302589476032794e-08, 'lambda': 7.530582562911367e-08, 'verbosity': 1, 'validate_parameters': True, 'objective': 'rank:map', 'eval_metric': 'map@100', 'tree_method': 'gpu_hist', 'random_state': 10}\n",
      "[0]\ttrain-map@100:0.01473+0.00005\ttest-map@100:0.01473+0.00012\n",
      "[1]\ttrain-map@100:0.03108+0.00022\ttest-map@100:0.03111+0.00153\n",
      "[2]\ttrain-map@100:0.03721+0.00031\ttest-map@100:0.03721+0.00148\n",
      "[3]\ttrain-map@100:0.03726+0.00034\ttest-map@100:0.03729+0.00149\n",
      "[4]\ttrain-map@100:0.43725+0.00037\ttest-map@100:0.43711+0.00415\n",
      "[5]\ttrain-map@100:0.45055+0.00255\ttest-map@100:0.45050+0.00362\n",
      "[6]\ttrain-map@100:0.50141+0.00413\ttest-map@100:0.50107+0.00448\n",
      "[7]\ttrain-map@100:0.50117+0.00413\ttest-map@100:0.50110+0.00458\n",
      "[8]\ttrain-map@100:0.49808+0.00722\ttest-map@100:0.49816+0.00717\n",
      "[9]\ttrain-map@100:0.49958+0.00803\ttest-map@100:0.49938+0.00751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-05-26 17:35:25,845]\u001B[0m Trial 2 finished with value: 0.4993809351396354 and parameters: {'sampling_method': 'gradient_based', 'booster': 'gbtree', 'max_depth': 3, 'eta': 0.9658354523530484, 'gamma': 1.5152916400990294e-08, 'min_child_weight': 68, 'subsample': 0.5024214920078056, 'colsample_bytree': 0.04087340605067627, 'colsample_bylevel': 0.000852725826709348, 'colsample_bynode': 0.5871113479525519, 'alpha': 2.302589476032794e-08, 'lambda': 7.530582562911367e-08}. Best is trial 0 with value: 0.5021159896284987.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HYPERTUNE] Best mean validation score: 0.4993809351396354\n",
      "[HYPERTUNE] Std of best validation score: 0.007513042243468559\n",
      "[HYPERTUNE] Chosen parameters: {'sampling_method': 'uniform', 'booster': 'gbtree', 'max_depth': 6, 'eta': 0.05296590248362138, 'gamma': 1.407093318830286e-08, 'min_child_weight': 72, 'subsample': 0.6548813503997307, 'colsample_bytree': 9.619270525408546e-06, 'colsample_bylevel': 0.0002880441562957349, 'colsample_bynode': 4.545685289609965e-06, 'alpha': 8.558451792576883e-05, 'lambda': 3.55797734655265e-07, 'verbosity': 1, 'validate_parameters': True, 'objective': 'rank:map', 'eval_metric': 'map@100', 'tree_method': 'gpu_hist', 'random_state': 10}\n",
      "[0]\ttrain-map@100:0.01522+0.00040\ttest-map@100:0.01523+0.00056\n",
      "[1]\ttrain-map@100:0.03291+0.00083\ttest-map@100:0.03288+0.00163\n",
      "[2]\ttrain-map@100:0.03846+0.00081\ttest-map@100:0.03844+0.00145\n",
      "[3]\ttrain-map@100:0.03836+0.00086\ttest-map@100:0.03841+0.00137\n",
      "[4]\ttrain-map@100:0.36801+0.01322\ttest-map@100:0.36693+0.01126\n",
      "[5]\ttrain-map@100:0.37942+0.00882\ttest-map@100:0.37849+0.00711\n",
      "[6]\ttrain-map@100:0.37718+0.00948\ttest-map@100:0.37595+0.00817\n",
      "[7]\ttrain-map@100:0.38001+0.00912\ttest-map@100:0.37885+0.00845\n",
      "[8]\ttrain-map@100:0.37398+0.00909\ttest-map@100:0.37270+0.00848\n",
      "[9]\ttrain-map@100:0.38747+0.00918\ttest-map@100:0.38618+0.00759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-05-26 17:35:55,264]\u001B[0m Trial 3 finished with value: 0.38618006334024385 and parameters: {'sampling_method': 'uniform', 'booster': 'gbtree', 'max_depth': 6, 'eta': 0.05296590248362138, 'gamma': 1.407093318830286e-08, 'min_child_weight': 72, 'subsample': 0.6548813503997307, 'colsample_bytree': 9.619270525408546e-06, 'colsample_bylevel': 0.0002880441562957349, 'colsample_bynode': 4.545685289609965e-06, 'alpha': 8.558451792576883e-05, 'lambda': 3.55797734655265e-07}. Best is trial 0 with value: 0.5021159896284987.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HYPERTUNE] Best mean validation score: 0.38618006334024385\n",
      "[HYPERTUNE] Std of best validation score: 0.007594981714118797\n",
      "[HYPERTUNE] Chosen parameters: {'sampling_method': 'gradient_based', 'booster': 'gbtree', 'max_depth': 1, 'eta': 0.024201098660059886, 'gamma': 0.009720396705141866, 'min_child_weight': 40, 'subsample': 0.8026328586956695, 'colsample_bytree': 6.354077522238227e-06, 'colsample_bylevel': 2.1352158990620478e-06, 'colsample_bynode': 6.518768884141251e-06, 'alpha': 2.71787136584183e-08, 'lambda': 1.0068900174839643e-08, 'verbosity': 1, 'validate_parameters': True, 'objective': 'rank:map', 'eval_metric': 'map@100', 'tree_method': 'gpu_hist', 'random_state': 10}\n",
      "[0]\ttrain-map@100:0.01266+0.00009\ttest-map@100:0.01266+0.00012\n",
      "[1]\ttrain-map@100:0.01359+0.00005\ttest-map@100:0.01360+0.00016\n",
      "[2]\ttrain-map@100:0.02006+0.00002\ttest-map@100:0.02007+0.00009\n",
      "[3]\ttrain-map@100:0.02016+0.00003\ttest-map@100:0.02017+0.00011\n",
      "[4]\ttrain-map@100:0.42411+0.00205\ttest-map@100:0.42397+0.00161\n",
      "[5]\ttrain-map@100:0.44556+0.00036\ttest-map@100:0.44560+0.00414\n",
      "[6]\ttrain-map@100:0.44546+0.00037\ttest-map@100:0.44550+0.00414\n",
      "[7]\ttrain-map@100:0.44563+0.00014\ttest-map@100:0.44562+0.00378\n",
      "[8]\ttrain-map@100:0.44557+0.00014\ttest-map@100:0.44556+0.00377\n",
      "[9]\ttrain-map@100:0.44550+0.00038\ttest-map@100:0.44552+0.00418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-05-26 17:36:21,202]\u001B[0m Trial 4 finished with value: 0.4455161081067304 and parameters: {'sampling_method': 'gradient_based', 'booster': 'gbtree', 'max_depth': 1, 'eta': 0.024201098660059886, 'gamma': 0.009720396705141866, 'min_child_weight': 40, 'subsample': 0.8026328586956695, 'colsample_bytree': 6.354077522238227e-06, 'colsample_bylevel': 2.1352158990620478e-06, 'colsample_bynode': 6.518768884141251e-06, 'alpha': 2.71787136584183e-08, 'lambda': 1.0068900174839643e-08}. Best is trial 0 with value: 0.5021159896284987.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HYPERTUNE] Best mean validation score: 0.4455161081067304\n",
      "[HYPERTUNE] Std of best validation score: 0.00418113271932924\n",
      "[HYPERTUNE] Chosen parameters: {'sampling_method': 'gradient_based', 'booster': 'gbtree', 'max_depth': 6, 'eta': 0.026864696311828657, 'gamma': 9.079395149911102e-06, 'min_child_weight': 32, 'subsample': 0.7365336611708589, 'colsample_bytree': 1.7608072334338495e-06, 'colsample_bylevel': 2.8714923252999378e-05, 'colsample_bynode': 0.7726361170415443, 'alpha': 0.3007448505005821, 'lambda': 6.308814856377941e-09, 'verbosity': 1, 'validate_parameters': True, 'objective': 'rank:map', 'eval_metric': 'map@100', 'tree_method': 'gpu_hist', 'random_state': 10}\n",
      "[0]\ttrain-map@100:0.01524+0.00042\ttest-map@100:0.01523+0.00057\n",
      "[1]\ttrain-map@100:0.03201+0.00057\ttest-map@100:0.03195+0.00109\n",
      "[2]\ttrain-map@100:0.03766+0.00061\ttest-map@100:0.03744+0.00114\n",
      "[3]\ttrain-map@100:0.03753+0.00053\ttest-map@100:0.03739+0.00106\n",
      "[4]\ttrain-map@100:0.35395+0.01011\ttest-map@100:0.35323+0.00984\n",
      "[5]\ttrain-map@100:0.36250+0.00397\ttest-map@100:0.36194+0.00461\n",
      "[6]\ttrain-map@100:0.35935+0.00436\ttest-map@100:0.35865+0.00509\n",
      "[7]\ttrain-map@100:0.35974+0.00586\ttest-map@100:0.35913+0.00669\n",
      "[8]\ttrain-map@100:0.35375+0.00569\ttest-map@100:0.35301+0.00650\n",
      "[9]\ttrain-map@100:0.36692+0.00551\ttest-map@100:0.36614+0.00536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-05-26 17:36:52,096]\u001B[0m Trial 5 finished with value: 0.3661394370990995 and parameters: {'sampling_method': 'gradient_based', 'booster': 'gbtree', 'max_depth': 6, 'eta': 0.026864696311828657, 'gamma': 9.079395149911102e-06, 'min_child_weight': 32, 'subsample': 0.7365336611708589, 'colsample_bytree': 1.7608072334338495e-06, 'colsample_bylevel': 2.8714923252999378e-05, 'colsample_bynode': 0.7726361170415443, 'alpha': 0.3007448505005821, 'lambda': 6.308814856377941e-09}. Best is trial 0 with value: 0.5021159896284987.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HYPERTUNE] Best mean validation score: 0.3661394370990995\n",
      "[HYPERTUNE] Std of best validation score: 0.005356401772828749\n",
      "[HYPERTUNE] Chosen parameters: {'sampling_method': 'gradient_based', 'booster': 'gbtree', 'max_depth': 1, 'eta': 0.2357774110388101, 'gamma': 3.526397787365607e-05, 'min_child_weight': 36, 'subsample': 0.4583046236747047, 'colsample_bytree': 0.029109737008087968, 'colsample_bylevel': 0.5883081280626057, 'colsample_bynode': 4.303625275500572e-05, 'alpha': 0.03632396452250383, 'lambda': 2.4123001256113716, 'verbosity': 1, 'validate_parameters': True, 'objective': 'rank:map', 'eval_metric': 'map@100', 'tree_method': 'gpu_hist', 'random_state': 10}\n",
      "[0]\ttrain-map@100:0.01266+0.00009\ttest-map@100:0.01266+0.00012\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_21760/3090888907.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miteration\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mXGB_hypertune\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcandidates_df\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcandidates_df\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget_df\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtarget_df\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_21760/3716326950.py\u001B[0m in \u001B[0;36mXGB_hypertune\u001B[1;34m(candidates_df, target_df, xgb_hyp_params_dict, num_trials, num_folds, early_stopping_rounds, save_folder, study_name, resume, with_datetime, telegram_notifications)\u001B[0m\n\u001B[0;32m    135\u001B[0m         )\n\u001B[0;32m    136\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 137\u001B[1;33m         \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mHypertuner\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdcandidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_trials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnum_trials\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    138\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    139\u001B[0m         \u001B[0mbest_iteration\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstudy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_trial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muser_attrs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'best_iteration'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\marti\\anaconda3\\envs\\recsys\\lib\\site-packages\\optuna\\study\\study.py\u001B[0m in \u001B[0;36moptimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    398\u001B[0m             )\n\u001B[0;32m    399\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 400\u001B[1;33m         _optimize(\n\u001B[0m\u001B[0;32m    401\u001B[0m             \u001B[0mstudy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    402\u001B[0m             \u001B[0mfunc\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\marti\\anaconda3\\envs\\recsys\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     64\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mn_jobs\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 66\u001B[1;33m             _optimize_sequential(\n\u001B[0m\u001B[0;32m     67\u001B[0m                 \u001B[0mstudy\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m                 \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\marti\\anaconda3\\envs\\recsys\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 163\u001B[1;33m             \u001B[0mtrial\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_run_trial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstudy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    164\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m             \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\marti\\anaconda3\\envs\\recsys\\lib\\site-packages\\optuna\\study\\_optimize.py\u001B[0m in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    211\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    212\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 213\u001B[1;33m         \u001B[0mvalue_or_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    214\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrialPruned\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    215\u001B[0m         \u001B[1;31m# TODO(mamu): Handle multi-objective cases.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_21760/3716326950.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m     16\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'[HYPERTUNE] Chosen parameters: '\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mchosen_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m                 xgb_model = xgb.cv(\n\u001B[0m\u001B[0;32m     19\u001B[0m                     \u001B[0mchosen_data\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m                     \u001B[0mdcandidates\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\marti\\anaconda3\\envs\\recsys\\lib\\site-packages\\xgboost\\training.py\u001B[0m in \u001B[0;36mcv\u001B[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle, custom_metric)\u001B[0m\n\u001B[0;32m    512\u001B[0m         \u001B[0mbooster\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    513\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 514\u001B[1;33m         \u001B[0mshould_break\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mafter_iteration\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbooster\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    515\u001B[0m         \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maggregated_cv\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    516\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstd\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mres\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\marti\\anaconda3\\envs\\recsys\\lib\\site-packages\\xgboost\\callback.py\u001B[0m in \u001B[0;36mafter_iteration\u001B[1;34m(self, model, epoch, dtrain, evals)\u001B[0m\n\u001B[0;32m    229\u001B[0m         \u001B[1;34m'''Function called after training iteration.'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    230\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_cv\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 231\u001B[1;33m             \u001B[0mscores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetric\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output_margin\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    232\u001B[0m             \u001B[0mscores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_aggcv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mscores\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    233\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maggregated_cv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mscores\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\marti\\anaconda3\\envs\\recsys\\lib\\site-packages\\xgboost\\training.py\u001B[0m in \u001B[0;36meval\u001B[1;34m(self, iteration, feval, output_margin)\u001B[0m\n\u001B[0;32m    227\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miteration\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_margin\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    228\u001B[0m         \u001B[1;34m'''Iterate through folds for eval'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 229\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miteration\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_margin\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mf\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcvfolds\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    230\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\marti\\anaconda3\\envs\\recsys\\lib\\site-packages\\xgboost\\training.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    227\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miteration\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_margin\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    228\u001B[0m         \u001B[1;34m'''Iterate through folds for eval'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 229\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miteration\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_margin\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mf\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcvfolds\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    230\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\marti\\anaconda3\\envs\\recsys\\lib\\site-packages\\xgboost\\training.py\u001B[0m in \u001B[0;36meval\u001B[1;34m(self, iteration, feval, output_margin)\u001B[0m\n\u001B[0;32m    213\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0meval\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miteration\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_margin\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    214\u001B[0m         \u001B[1;34m\"\"\"\"Evaluate the CVPack for one iteration.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 215\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meval_set\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwatchlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miteration\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_margin\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    216\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\Users\\marti\\anaconda3\\envs\\recsys\\lib\\site-packages\\xgboost\\core.py\u001B[0m in \u001B[0;36meval_set\u001B[1;34m(self, evals, iteration, feval, output_margin)\u001B[0m\n\u001B[0;32m   1802\u001B[0m         \u001B[0mmsg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mctypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mc_char_p\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1803\u001B[0m         _check_call(\n\u001B[1;32m-> 1804\u001B[1;33m             _LIB.XGBoosterEvalOneIter(\n\u001B[0m\u001B[0;32m   1805\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1806\u001B[0m                 \u001B[0mctypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mc_int\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miteration\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "params, iteration = XGB_hypertune(candidates_df=candidates_df, target_df=target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Corrected_submission.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "662236ff4a3599a6369637d46054e6465a367b5e2f2cb09ee0460010b626acba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('recsys')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}