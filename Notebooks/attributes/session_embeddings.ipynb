{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from Pipeline.recommender_tuning import hypertune\n",
    "from Pipeline.data_extraction import get_dataframes\n",
    "from Pipeline.matrices_creation import get_URM_split_val, create_URM\n",
    "from DressipiChallenge.Recommenders.Neural.MultVAERecommender import MultVAERecommender_OptimizerMask\n",
    "from Pipeline.optuna_utils import Integer, Real, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVs read\n"
     ]
    }
   ],
   "source": [
    "item_features_df, train_sessions_df, train_purchases_df, test_sessions_df, candidate_items_df = get_dataframes(\"../../\")\n",
    "\n",
    "URM_train, URM_val_views, URM_val_purch, mapped_items_to_ignore, mapped_val_sessions_arr, val_session_mapping, item_mapping = get_URM_split_val(\n",
    "    item_features_df=item_features_df,\n",
    "    train_purchases_df=train_purchases_df,\n",
    "    train_sessions_df=train_sessions_df,\n",
    "    val_start_ts='2021-05-01',\n",
    "    val_end_ts='2021-06-01',\n",
    "    unique_interactions=True,\n",
    "    abs_half_life=365,\n",
    "    cyclic_decay=False,\n",
    "    purch_weight=1,\n",
    "    view_weight=0.5,\n",
    "    score_graph=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultVAERecommender: URM Detected 477 ( 2.0%) items with no interactions.\n"
     ]
    }
   ],
   "source": [
    "multvae = MultVAERecommender_OptimizerMask(URM_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyp = {'epochs': 1, 'learning_rate': 1.4396337313314092e-05, 'l2_reg': 1.9803558930283507e-06, 'dropout': 0.7726522034872121, 'total_anneal_steps': 388484, 'anneal_cap': 0.266817776801911, 'batch_size': 128, 'encoding_size': 227, 'next_layer_size_multiplier': 6, 'max_n_hidden_layers': 2, 'max_parameters': 1750000000.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultVAERecommender: Architecture: [227, 1362, 23691]\n",
      "MultVAERecommender: Using default Temp folder './result_experiments/__Temp_MultVAERecommender_17336/'\n",
      "MultVAERecommender: Saving model in file './result_experiments/__Temp_MultVAERecommender_17336/_best_model'\n",
      "MultVAERecommender: Saving complete\n",
      "MultVAERecommender: Epoch 1 of 1. Elapsed time 6.11 min\n",
      "MultVAERecommender: Saving model in file './result_experiments/__Temp_MultVAERecommender_17336/_best_model'\n",
      "MultVAERecommender: Saving complete\n",
      "MultVAERecommender: Terminating at epoch 1. Elapsed time 6.14 min\n",
      "MultVAERecommender: Loading model from file './result_experiments/__Temp_MultVAERecommender_17336/_best_model'\n",
      "INFO:tensorflow:Restoring parameters from ./result_experiments/__Temp_MultVAERecommender_17336/_best_model/.session/session\n",
      "MultVAERecommender: Loading complete\n",
      "MultVAERecommender: Cleaning temporary files from './result_experiments/__Temp_MultVAERecommender_17336/'\n"
     ]
    }
   ],
   "source": [
    "multvae.fit(**best_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "X = multvae.URM_train[0]\n",
    "\n",
    "if sparse.isspmatrix(X):\n",
    "    X = X.toarray()\n",
    "X = X.astype('float32')\n",
    "\n",
    "feed_dict = {multvae.vae.input_ph: X}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09989955, -0.01976695, -0.07885621,  0.08938596, -0.0844129 ,\n",
       "        -0.10481874, -0.14289923,  0.02802889, -0.10555656, -0.10308403,\n",
       "        -0.10784927,  0.01435503,  0.12524645, -0.09677149,  0.00658246,\n",
       "         0.05537899, -0.03680438,  0.07453355,  0.12719691, -0.07135529,\n",
       "        -0.09758721, -0.12293227, -0.08562053,  0.01820915, -0.05475412,\n",
       "        -0.06142215,  0.04265151,  0.15643267, -0.05650007, -0.03106585,\n",
       "        -0.07743905,  0.01486019, -0.1115837 ,  0.10318891, -0.03090213,\n",
       "         0.03481588,  0.04729668,  0.15693668,  0.07278181,  0.17468531,\n",
       "        -0.06920554, -0.16824917, -0.03436874,  0.05336907, -0.17737909,\n",
       "        -0.04835016, -0.03374434,  0.1633553 ,  0.03540198,  0.09597493,\n",
       "         0.11361274, -0.13205245,  0.03426874, -0.11482158,  0.09487895,\n",
       "         0.09321387,  0.09976232,  0.01830675,  0.06262195,  0.06669343,\n",
       "         0.02472619, -0.06360423, -0.02154977,  0.12757298,  0.09411594,\n",
       "        -0.15562224, -0.03077425,  0.15879841, -0.03128173, -0.01961995,\n",
       "         0.02033818,  0.20028529, -0.13322334,  0.06536908,  0.04671687,\n",
       "        -0.00635011, -0.05576599, -0.0822741 , -0.20031476, -0.05822579,\n",
       "         0.11163045, -0.10122233, -0.13401447,  0.04753497, -0.06523453,\n",
       "        -0.10396947, -0.15675104,  0.16591066,  0.08074156,  0.09283065,\n",
       "        -0.1192551 ,  0.04683249,  0.10005128, -0.09698755, -0.17652963,\n",
       "        -0.11827061,  0.00379665,  0.15216643, -0.08454505, -0.1388027 ,\n",
       "         0.05027609, -0.16148202, -0.06892047, -0.12191275,  0.07370438,\n",
       "        -0.09012633,  0.03781305,  0.14322181,  0.08338396,  0.0933229 ,\n",
       "         0.00083447,  0.15162706,  0.06497445,  0.04195979, -0.04606828,\n",
       "         0.01750436, -0.06294926, -0.0182597 ,  0.07772785,  0.07867526,\n",
       "        -0.03536329, -0.13693057,  0.04974578,  0.01456834, -0.05682016,\n",
       "         0.06827328,  0.12055939,  0.09274579, -0.09003192, -0.02238552,\n",
       "        -0.06946183, -0.09121461, -0.12323189, -0.04696631,  0.00256507,\n",
       "         0.05197378,  0.03156089,  0.09059833,  0.04892578,  0.09841371,\n",
       "         0.12331658,  0.00566905,  0.06659147,  0.09840234, -0.07571771,\n",
       "        -0.00873095, -0.04470551,  0.10310605, -0.13253246, -0.07173546,\n",
       "         0.01562739,  0.01915425, -0.08213925, -0.14941065,  0.18115585,\n",
       "         0.09883618, -0.08397312, -0.09354929,  0.0445078 ,  0.00581312,\n",
       "         0.11637909, -0.00694988,  0.07934162, -0.10680483, -0.04298264,\n",
       "         0.12535197,  0.07126985, -0.13243832, -0.09712877,  0.03633991,\n",
       "        -0.08368699, -0.00751264, -0.0056041 ,  0.1705488 ,  0.06622662,\n",
       "        -0.04030669, -0.11596278, -0.16890088,  0.10277005, -0.09414493,\n",
       "        -0.10838589, -0.00729776,  0.12549311, -0.14148085, -0.11728821,\n",
       "         0.1351738 ,  0.04666147, -0.1474575 ,  0.10449263, -0.11375442,\n",
       "         0.04140545,  0.01625654,  0.14098601,  0.03077433,  0.14132705,\n",
       "        -0.09531718,  0.06173252,  0.13035071, -0.2133259 , -0.06373461,\n",
       "        -0.02549117, -0.05366478, -0.1752203 ,  0.10135849, -0.03377628,\n",
       "        -0.07846557,  0.03005299, -0.11509477, -0.10031166,  0.12134247,\n",
       "        -0.04481141, -0.07290769, -0.00192036,  0.13192016, -0.04791791,\n",
       "         0.00291034, -0.00622914, -0.0236088 ,  0.05396619,  0.06176761,\n",
       "         0.11050501, -0.1509472 , -0.03042893,  0.11229089, -0.08487044,\n",
       "         0.15415804, -0.01043324]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = multvae.sess.graph.get_tensor_by_name(multvae.vae.embeddings_name)\n",
    "output_values = multvae.sess.run(output, feed_dict=feed_dict)\n",
    "output_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from DressipiChallenge.Pipeline.data_splitting import split_dataframes_val\n",
    "from DressipiChallenge.Pipeline.matrices_creation import create_csr_matrix\n",
    "\n",
    "def get_vae_embeddings(folder_path,  batch_size=100, save_path=\"./session_embeddigs.parquet\", is_test = False):\n",
    "    # ohhh the misery\n",
    "\n",
    "    val_end_ts = '2021-07-01' if is_test else '2021-06-01'\n",
    "    val_start_ts = '2021-06-01' if is_test else '2021-05-01'\n",
    "\n",
    "    weighted_train_set_df, val_purch_df, val_views_df, train_session_mapping, \\\n",
    "    val_session_mapping, item_mapping, mapped_items_to_ignore, mapped_val_sessions_arr = split_dataframes_val(\n",
    "        train_sessions_df, train_purchases_df, item_features_df,\n",
    "        val_start_ts=val_start_ts, val_end_ts=val_end_ts,\n",
    "        unique_interactions=True, view_weight=1, purch_weight=0, abs_half_life=None,\n",
    "        cyclic_decay=False, score_graph=False\n",
    "    )\n",
    "\n",
    "    URM_train = create_csr_matrix(weighted_train_set_df, len(train_session_mapping), len(item_mapping))\n",
    "    URM_val_views = create_csr_matrix(val_views_df, len(val_session_mapping), len(item_mapping))\n",
    "\n",
    "    multvae = MultVAERecommender_OptimizerMask(URM_train)\n",
    "    multvae.load_model(folder_path)\n",
    "\n",
    "    embeddings_train = np.zeros(shape=(len(train_session_mapping), multvae.p_dims[0]))\n",
    "\n",
    "    processed = 0\n",
    "\n",
    "    for _, st_idx in enumerate(range(0, 200, batch_size)):\n",
    "\n",
    "        end_idx = min(st_idx + batch_size, len(train_session_mapping))\n",
    "        X = URM_train[st_idx:end_idx]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        output = multvae.sess.graph.get_tensor_by_name(multvae.vae.embeddings_name)\n",
    "        feed_dict = {multvae.vae.input_ph: X,\n",
    "                     multvae.vae.is_training_ph: 1}\n",
    "        output_values = multvae.sess.run(output, feed_dict=feed_dict)\n",
    "        embeddings_train[st_idx:end_idx] = output_values\n",
    "\n",
    "        processed += end_idx-st_idx\n",
    "        print(\"Processed {0} train user.\".format(processed))\n",
    "\n",
    "    df_train = pd.DataFrame(embeddings_train)\n",
    "    df_train.to_csv(save_path, index=False)\n",
    "\n",
    "    print(\"Saved train. Continuning with test.\")\n",
    "    # Partial train to not lose data...\n",
    "\n",
    "    embeddings_test = np.zeros(shape=(len(val_session_mapping), multvae.p_dims[0]))\n",
    "\n",
    "    processed = 0\n",
    "\n",
    "    for _, st_idx in enumerate(range(0, 200, batch_size)):\n",
    "\n",
    "        end_idx = min(st_idx + batch_size, len(val_session_mapping))\n",
    "        X = URM_val_views[st_idx:end_idx]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        output = multvae.sess.graph.get_tensor_by_name(multvae.vae.embeddings_name)\n",
    "        feed_dict = {multvae.vae.input_ph: X,\n",
    "                     multvae.vae.is_training_ph: 1}\n",
    "        output_values = multvae.sess.run(output, feed_dict=feed_dict)\n",
    "        embeddings_test[st_idx:end_idx] = output_values\n",
    "\n",
    "        processed += end_idx-st_idx\n",
    "        print(\"Processed {0} test user.\".format(processed))\n",
    "\n",
    "    df_test = pd.DataFrame(embeddings_test)\n",
    "    \n",
    "    # merge both\n",
    "\n",
    "    val_inverse = {k:v for v,k in val_session_mapping.items()}\n",
    "    train_inverse = {k:v for v,k in train_session_mapping.items()}\n",
    "\n",
    "    df_train.insert(loc=0, column=\"session_id\", value=[train_inverse[x] for x in np.arange(len(df_train))])\n",
    "    df_test.insert(loc=0, column=\"session_id\", value=[val_inverse[x] for x in np.arange(len(df_test))])\n",
    "\n",
    "    df_test = pd.concat([df_train, df_test]).reset_index(drop=True)\n",
    "    df_test.to_parquet(save_path, index=False)\n",
    "\n",
    "    print(\"Saved test.\")\n",
    "\n",
    "    return df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultVAERecommender: URM Detected 600 ( 2.5%) items with no interactions.\n",
      "MultVAERecommender: Loading model from file './owo.h5MultVAERecommender'\n",
      "INFO:tensorflow:Restoring parameters from ./owo.h5MultVAERecommender/.session/session\n",
      "MultVAERecommender: Loading complete\n",
      "Processed 100 train user.\n",
      "Processed 200 train user.\n",
      "Saved train. Continuning with test.\n",
      "Processed 100 test user.\n",
      "Processed 200 test user.\n",
      "Saved test.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.079773</td>\n",
       "      <td>0.452049</td>\n",
       "      <td>-0.250728</td>\n",
       "      <td>-0.070084</td>\n",
       "      <td>0.200194</td>\n",
       "      <td>-1.441675</td>\n",
       "      <td>-1.983052</td>\n",
       "      <td>0.233127</td>\n",
       "      <td>-0.151445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179735</td>\n",
       "      <td>-1.172273</td>\n",
       "      <td>0.070427</td>\n",
       "      <td>-0.116233</td>\n",
       "      <td>0.128644</td>\n",
       "      <td>0.349428</td>\n",
       "      <td>1.009601</td>\n",
       "      <td>-0.071348</td>\n",
       "      <td>-0.129234</td>\n",
       "      <td>1.510903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>-1.779117</td>\n",
       "      <td>-1.147733</td>\n",
       "      <td>-0.274971</td>\n",
       "      <td>0.682536</td>\n",
       "      <td>-1.149518</td>\n",
       "      <td>0.595269</td>\n",
       "      <td>0.810294</td>\n",
       "      <td>-0.690703</td>\n",
       "      <td>-0.197307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510440</td>\n",
       "      <td>-1.199814</td>\n",
       "      <td>-0.020504</td>\n",
       "      <td>0.353472</td>\n",
       "      <td>-0.771306</td>\n",
       "      <td>-0.277225</td>\n",
       "      <td>0.149223</td>\n",
       "      <td>-0.062017</td>\n",
       "      <td>0.558752</td>\n",
       "      <td>0.956635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>-1.060449</td>\n",
       "      <td>-0.557475</td>\n",
       "      <td>-1.038367</td>\n",
       "      <td>0.971215</td>\n",
       "      <td>-1.896285</td>\n",
       "      <td>-0.153937</td>\n",
       "      <td>-0.212554</td>\n",
       "      <td>-1.468928</td>\n",
       "      <td>-0.300046</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.169792</td>\n",
       "      <td>-0.737722</td>\n",
       "      <td>-1.433205</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>0.021403</td>\n",
       "      <td>-0.574306</td>\n",
       "      <td>-0.187727</td>\n",
       "      <td>0.627984</td>\n",
       "      <td>-0.909470</td>\n",
       "      <td>0.149374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>1.870649</td>\n",
       "      <td>-1.011784</td>\n",
       "      <td>1.193372</td>\n",
       "      <td>1.227687</td>\n",
       "      <td>-0.078799</td>\n",
       "      <td>-1.017636</td>\n",
       "      <td>1.449390</td>\n",
       "      <td>0.878878</td>\n",
       "      <td>-1.282964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322996</td>\n",
       "      <td>-0.184029</td>\n",
       "      <td>0.690260</td>\n",
       "      <td>0.265269</td>\n",
       "      <td>0.176457</td>\n",
       "      <td>1.338422</td>\n",
       "      <td>1.385663</td>\n",
       "      <td>-0.717638</td>\n",
       "      <td>2.053130</td>\n",
       "      <td>0.923624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.437075</td>\n",
       "      <td>-0.820023</td>\n",
       "      <td>0.692018</td>\n",
       "      <td>0.030970</td>\n",
       "      <td>0.645132</td>\n",
       "      <td>-0.841275</td>\n",
       "      <td>-0.541000</td>\n",
       "      <td>0.617516</td>\n",
       "      <td>-0.461960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423458</td>\n",
       "      <td>0.065053</td>\n",
       "      <td>1.738762</td>\n",
       "      <td>-1.165564</td>\n",
       "      <td>0.750926</td>\n",
       "      <td>1.222507</td>\n",
       "      <td>0.559896</td>\n",
       "      <td>-0.775158</td>\n",
       "      <td>1.005858</td>\n",
       "      <td>2.995511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4439680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>4439823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>4439898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>4439949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>4439986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id         0         1         2         3         4  \\\n",
       "0                3 -0.079773  0.452049 -0.250728 -0.070084  0.200194   \n",
       "1               13 -1.779117 -1.147733 -0.274971  0.682536 -1.149518   \n",
       "2               18 -1.060449 -0.557475 -1.038367  0.971215 -1.896285   \n",
       "3               19  1.870649 -1.011784  1.193372  1.227687 -0.078799   \n",
       "4               24 -0.437075 -0.820023  0.692018  0.030970  0.645132   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "999995     4439680  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999996     4439823  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999997     4439898  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999998     4439949  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999999     4439986  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "               5         6         7         8  ...       217       218  \\\n",
       "0      -1.441675 -1.983052  0.233127 -0.151445  ...  0.179735 -1.172273   \n",
       "1       0.595269  0.810294 -0.690703 -0.197307  ... -0.510440 -1.199814   \n",
       "2      -0.153937 -0.212554 -1.468928 -0.300046  ... -2.169792 -0.737722   \n",
       "3      -1.017636  1.449390  0.878878 -1.282964  ...  0.322996 -0.184029   \n",
       "4      -0.841275 -0.541000  0.617516 -0.461960  ...  0.423458  0.065053   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "999995  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "999996  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "999997  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "999998  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "999999  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "\n",
       "             219       220       221       222       223       224       225  \\\n",
       "0       0.070427 -0.116233  0.128644  0.349428  1.009601 -0.071348 -0.129234   \n",
       "1      -0.020504  0.353472 -0.771306 -0.277225  0.149223 -0.062017  0.558752   \n",
       "2      -1.433205  0.835977  0.021403 -0.574306 -0.187727  0.627984 -0.909470   \n",
       "3       0.690260  0.265269  0.176457  1.338422  1.385663 -0.717638  2.053130   \n",
       "4       1.738762 -1.165564  0.750926  1.222507  0.559896 -0.775158  1.005858   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999996  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999997  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999998  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999999  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             226  \n",
       "0       1.510903  \n",
       "1       0.956635  \n",
       "2       0.149374  \n",
       "3       0.923624  \n",
       "4       2.995511  \n",
       "...          ...  \n",
       "999995  0.000000  \n",
       "999996  0.000000  \n",
       "999997  0.000000  \n",
       "999998  0.000000  \n",
       "999999  0.000000  \n",
       "\n",
       "[1000000 rows x 228 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vae_embeddings(\"./owo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.079773</td>\n",
       "      <td>0.452049</td>\n",
       "      <td>-0.250728</td>\n",
       "      <td>-0.070084</td>\n",
       "      <td>0.200194</td>\n",
       "      <td>-1.441675</td>\n",
       "      <td>-1.983052</td>\n",
       "      <td>0.233127</td>\n",
       "      <td>-0.151445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179735</td>\n",
       "      <td>-1.172273</td>\n",
       "      <td>0.070427</td>\n",
       "      <td>-0.116233</td>\n",
       "      <td>0.128644</td>\n",
       "      <td>0.349428</td>\n",
       "      <td>1.009601</td>\n",
       "      <td>-0.071348</td>\n",
       "      <td>-0.129234</td>\n",
       "      <td>1.510903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>-1.779117</td>\n",
       "      <td>-1.147733</td>\n",
       "      <td>-0.274971</td>\n",
       "      <td>0.682536</td>\n",
       "      <td>-1.149518</td>\n",
       "      <td>0.595269</td>\n",
       "      <td>0.810294</td>\n",
       "      <td>-0.690703</td>\n",
       "      <td>-0.197307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510440</td>\n",
       "      <td>-1.199814</td>\n",
       "      <td>-0.020504</td>\n",
       "      <td>0.353472</td>\n",
       "      <td>-0.771306</td>\n",
       "      <td>-0.277225</td>\n",
       "      <td>0.149223</td>\n",
       "      <td>-0.062017</td>\n",
       "      <td>0.558752</td>\n",
       "      <td>0.956635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>-1.060449</td>\n",
       "      <td>-0.557475</td>\n",
       "      <td>-1.038367</td>\n",
       "      <td>0.971215</td>\n",
       "      <td>-1.896285</td>\n",
       "      <td>-0.153937</td>\n",
       "      <td>-0.212554</td>\n",
       "      <td>-1.468928</td>\n",
       "      <td>-0.300046</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.169792</td>\n",
       "      <td>-0.737722</td>\n",
       "      <td>-1.433205</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>0.021403</td>\n",
       "      <td>-0.574306</td>\n",
       "      <td>-0.187727</td>\n",
       "      <td>0.627984</td>\n",
       "      <td>-0.909470</td>\n",
       "      <td>0.149374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>1.870649</td>\n",
       "      <td>-1.011784</td>\n",
       "      <td>1.193372</td>\n",
       "      <td>1.227687</td>\n",
       "      <td>-0.078799</td>\n",
       "      <td>-1.017636</td>\n",
       "      <td>1.449390</td>\n",
       "      <td>0.878878</td>\n",
       "      <td>-1.282964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322996</td>\n",
       "      <td>-0.184029</td>\n",
       "      <td>0.690260</td>\n",
       "      <td>0.265269</td>\n",
       "      <td>0.176457</td>\n",
       "      <td>1.338422</td>\n",
       "      <td>1.385663</td>\n",
       "      <td>-0.717638</td>\n",
       "      <td>2.053130</td>\n",
       "      <td>0.923624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.437075</td>\n",
       "      <td>-0.820023</td>\n",
       "      <td>0.692018</td>\n",
       "      <td>0.030970</td>\n",
       "      <td>0.645132</td>\n",
       "      <td>-0.841275</td>\n",
       "      <td>-0.541000</td>\n",
       "      <td>0.617516</td>\n",
       "      <td>-0.461960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423458</td>\n",
       "      <td>0.065053</td>\n",
       "      <td>1.738762</td>\n",
       "      <td>-1.165564</td>\n",
       "      <td>0.750926</td>\n",
       "      <td>1.222507</td>\n",
       "      <td>0.559896</td>\n",
       "      <td>-0.775158</td>\n",
       "      <td>1.005858</td>\n",
       "      <td>2.995511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>4439680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>4439823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>4439898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>4439949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>4439986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id         0         1         2         3         4  \\\n",
       "0                3 -0.079773  0.452049 -0.250728 -0.070084  0.200194   \n",
       "1               13 -1.779117 -1.147733 -0.274971  0.682536 -1.149518   \n",
       "2               18 -1.060449 -0.557475 -1.038367  0.971215 -1.896285   \n",
       "3               19  1.870649 -1.011784  1.193372  1.227687 -0.078799   \n",
       "4               24 -0.437075 -0.820023  0.692018  0.030970  0.645132   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "999995     4439680  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999996     4439823  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999997     4439898  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999998     4439949  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999999     4439986  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "               5         6         7         8  ...       217       218  \\\n",
       "0      -1.441675 -1.983052  0.233127 -0.151445  ...  0.179735 -1.172273   \n",
       "1       0.595269  0.810294 -0.690703 -0.197307  ... -0.510440 -1.199814   \n",
       "2      -0.153937 -0.212554 -1.468928 -0.300046  ... -2.169792 -0.737722   \n",
       "3      -1.017636  1.449390  0.878878 -1.282964  ...  0.322996 -0.184029   \n",
       "4      -0.841275 -0.541000  0.617516 -0.461960  ...  0.423458  0.065053   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "999995  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "999996  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "999997  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "999998  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "999999  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "\n",
       "             219       220       221       222       223       224       225  \\\n",
       "0       0.070427 -0.116233  0.128644  0.349428  1.009601 -0.071348 -0.129234   \n",
       "1      -0.020504  0.353472 -0.771306 -0.277225  0.149223 -0.062017  0.558752   \n",
       "2      -1.433205  0.835977  0.021403 -0.574306 -0.187727  0.627984 -0.909470   \n",
       "3       0.690260  0.265269  0.176457  1.338422  1.385663 -0.717638  2.053130   \n",
       "4       1.738762 -1.165564  0.750926  1.222507  0.559896 -0.775158  1.005858   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999996  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999997  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999998  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "999999  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             226  \n",
       "0       1.510903  \n",
       "1       0.956635  \n",
       "2       0.149374  \n",
       "3       0.923624  \n",
       "4       2.995511  \n",
       "...          ...  \n",
       "999995  0.000000  \n",
       "999996  0.000000  \n",
       "999997  0.000000  \n",
       "999998  0.000000  \n",
       "999999  0.000000  \n",
       "\n",
       "[1000000 rows x 228 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"./session_embeddigs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_embeddings_on_train = pd.read_csv(\"../../Dataset/embeddings_session.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_val = session_embeddings_on_train.loc[session_embeddings_on_train.session_id.isin(list(val_session_mapping.keys()))]\n",
    "session_val.to_csv(\"../../Dataset/session_val_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del session_embeddings_on_train\n",
    "del session_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_embeddings_on_val = pd.read_csv(\"../../Dataset/embeddings_session_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_train_test = session_embeddings_on_val.loc[~session_embeddings_on_val.session_id.isin(list(val_session_mapping.keys()))]\n",
    "session_test = session_train_test.loc[~session_train_test.session_id.isin(list(train_sessions_df.session_id.unique()))]\n",
    "session_test.to_csv(\"../../Dataset/session_test_embeddings.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d88d5ac213475c5bc29f87cd91e6c6ecf55472304351e26597a498055d7f38e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('recsys')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
